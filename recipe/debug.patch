diff --git a/src/dials/algorithms/symmetry/cosym/__init__.py b/src/dials/algorithms/symmetry/cosym/__init__.py
index 2a513d165..7815788b5 100644
--- a/src/dials/algorithms/symmetry/cosym/__init__.py
+++ b/src/dials/algorithms/symmetry/cosym/__init__.py
@@ -400,6 +400,11 @@ def _reindexing_ops(
             # if seed dataset was specified, use the reindexing op xyz as seed
             sel = np.where(dataset_ids == self.seed_dataset)
             xis = np.array([coords[sel][0]])
+            logger.warning(f"{self.seed_dataset=}")
+            logger.warning(f"{dataset_ids=}")
+            logger.warning(f"{sel=}")
+            logger.warning(f"{xis=}")
+            logger.warning(f"{coords[sel]=}")
         else:
             # choose a high density point as seed
             X = coords
@@ -413,16 +418,21 @@ def _reindexing_ops(
         coordstr = ",".join(str(round(i, 4)) for i in xis[0])
         logger.debug(f"Coordinate of cluster seed dataset: {coordstr}")
 
+        xis_mean_history = [xis.mean(axis=0)]
         for j in range(n_datasets):
             sel = np.where(dataset_ids == j)
             X = coords[sel]
+            print(len(X))
             # Find nearest neighbour in cosine-space to the current cluster centroid
             nbrs = NearestNeighbors(
                 n_neighbors=min(1, len(X)), algorithm="brute", metric="cosine"
+                # n_neighbors=2, algorithm="brute", metric="cosine"
             ).fit(X)
             distances, indices = nbrs.kneighbors([xis.mean(axis=0)])
+            print(f"{j=} {distances=} {indices=}")
             k = indices[0][0]
             xis = np.append(xis, [X[k]], axis=0)
+            xis_mean_history.append(xis.mean(axis=0))
             for partition in cosets.partitions:
                 if sym_ops[k] in partition:
                     cb_op = sgtbx.change_of_basis_op(partition[0]).new_denominators(
@@ -434,7 +444,16 @@ def _reindexing_ops(
                         ).as_xyz()
                     )
                     break
-
+        if 0:
+            import matplotlib.pyplot as plt
+            # breakpoint()
+            plt.scatter(coords[:, 0], coords[:, 1])
+            xis_mean_history = np.vstack(xis_mean_history)
+            print(f"{xis_mean_history=}")
+            plt.plot(xis_mean_history[:, 0], xis_mean_history[:, 1], c="r")
+            plt.show()
+
+        logger.warning(f"{reindexing_ops=}")
         return reindexing_ops
 
     def as_dict(self):
@@ -873,6 +892,16 @@ def extract_reference_intensities(params: iotbx.phil.scope_extract) -> miller.ar
         * group["cb_op_inp_best"]
     )
 
+    # reference_intensities = reference_intensities.change_basis(ref_cb_op)
+    # print("1:", reference_intensities.size())
+    # reference_intensities = reference_intensities.expand_to_p1()
+    # print("2:", reference_intensities.size())
+    # reference_intensities = reference_intensities.as_non_anomalous_array()
+    # print("3:", reference_intensities.size())
+    # reference_intensities = reference_intensities.merge_equivalents().array()
+    # print("4:", reference_intensities.size())
+    # reference_intensities = reference_intensities.customized_copy(space_group_info=sgtbx.space_group_info("P1"))
+
     reference_intensities = (
         reference_intensities.change_basis(
             ref_cb_op,
@@ -882,6 +911,7 @@ def extract_reference_intensities(params: iotbx.phil.scope_extract) -> miller.ar
         .merge_equivalents()
         .array()
     )
+    # breakpoint()
     if not reference_intensities.sigmas():
         reference_intensities.set_sigmas(flex.double(reference_intensities.size(), 1))
-    return reference_intensities, initial_space_group_info
+    return reference_intensities, initial_space_group_info, ref_cb_op
diff --git a/src/dials/algorithms/symmetry/cosym/target.py b/src/dials/algorithms/symmetry/cosym/target.py
index 53c467024..103b9cc06 100644
--- a/src/dials/algorithms/symmetry/cosym/target.py
+++ b/src/dials/algorithms/symmetry/cosym/target.py
@@ -204,6 +204,7 @@ def _compute_rij_wij(self, use_cache=True):
             for j, selection in enumerate(slices):
                 # map (i, j) to a column in all_intensities
                 column = np.ravel_multi_index((i, j), (n_sym_ops, n_lattices))
+                print(f"{i=} {j=} {n_sym_ops=} {n_lattices=} {column=}")
                 epsilon_equals_one = eps[selection] == 1
                 valid_mil_ind = mil_ind[selection][epsilon_equals_one]
                 valid_intensities = intensities[selection][epsilon_equals_one]
@@ -248,6 +249,18 @@ def _compute_rij_wij(self, use_cache=True):
         else:
             wij = None
 
+        for i in range(n_lattices):
+            j = 13
+            # for j in range(i+1, n_lattices):
+            for ik in range(n_sym_ops):
+                for jk in range(n_sym_ops):
+                    if self._weights:
+                        print(i, j, ik, jk, 
+                                rij[ik * n_lattices + i, jk * n_lattices + j],
+                                wij[ik * n_lattices + i, jk * n_lattices + j],
+                                )
+                    else:
+                        print(i, j, ik, jk, rij[ik * n_lattices + i, jk * n_lattices + j])
         return rij, wij
 
     def compute_functional(self, x: np.ndarray) -> float:
diff --git a/src/dials/command_line/cosym.py b/src/dials/command_line/cosym.py
index 1a1db96a0..a3e3e1a4e 100644
--- a/src/dials/command_line/cosym.py
+++ b/src/dials/command_line/cosym.py
@@ -99,22 +99,6 @@ def __init__(self, experiments, reflections, params=None):
             params = phil_scope.extract()
         self.params = params
 
-        reference_intensities = None
-        if self.params.reference:
-            reference_intensities, space_group_info = extract_reference_intensities(
-                params
-            )
-            if self.params.space_group and (
-                self.params.space_group.type().number()
-                != space_group_info.type().number()
-            ):
-                # N.B. space group phil options are actually space_group_info objects
-                raise ValueError(
-                    f"Input space group ({self.params.space_group}) does not match space group from reference file ({space_group_info})"
-                )
-            logger.info(f"Using space group {space_group_info} from reference")
-            self.params.space_group = space_group_info
-
         self._reflections = []
         for refl, expt in zip(reflections, experiments):
             sel = get_selection_for_valid_image_ranges(refl, expt)
@@ -150,6 +134,8 @@ def __init__(self, experiments, reflections, params=None):
             params.relative_length_tolerance,
             params.absolute_angle_tolerance,
         )
+        print(f"#### cb_ops={[str(c) for c in cb_ops]} ####")
+        # print(f"{str(self._ref_cb_op)=}")
         exclude = [
             expt.identifier
             for expt, cb_op in zip(self._experiments, cb_ops)
@@ -186,11 +172,33 @@ def __init__(self, experiments, reflections, params=None):
         datasets = [
             ma.as_non_anomalous_array().merge_equivalents().array() for ma in datasets
         ]
-        if reference_intensities:
+        if self.params.reference:
+            reference_intensities, space_group_info, self._ref_cb_op = extract_reference_intensities(
+                params
+            )
+            reference_intensities = reference_intensities.change_basis(self._ref_cb_op.inverse()).change_basis(cb_ops[0])
+            print(f"{reference_intensities=}")
+            if self.params.space_group and (
+                self.params.space_group.type().number()
+                != space_group_info.type().number()
+            ):
+                # N.B. space group phil options are actually space_group_info objects
+                raise ValueError(
+                    f"Input space group ({self.params.space_group}) does not match space group from reference file ({space_group_info})"
+                )
+            logger.info(f"Using space group {space_group_info} from reference")
+            self.params.space_group = space_group_info
+            self.reference_intensities = reference_intensities
+
             datasets.append(reference_intensities)
+            print("*" * 80)
+            for dset in datasets:
+                print(dset)
+            print("*" * 80)
             self.cosym_analysis = CosymAnalysis(
                 datasets, self.params, seed_dataset=len(datasets) - 1
             )
+            self.datasets = datasets
         else:
             self.cosym_analysis = CosymAnalysis(datasets, self.params)
 
@@ -209,6 +217,14 @@ def run(self):
         self.cosym_analysis.run()
         reindexing_ops = self.cosym_analysis.reindexing_ops
         datasets_ = list(set(self.cosym_analysis.dataset_ids))
+        datasets = self.cosym_analysis.input_intensities
+        print(f"{reindexing_ops=}")
+        # # breakpoint()
+        # for i, (dset, cb_op) in enumerate(zip(datasets[:-1], reindexing_ops[:-1])):
+        #     dset = dset.change_basis(sgtbx.change_of_basis_op(cb_op)).map_to_asu()
+        #     ma1, ma2 = dset.common_sets(datasets[-1])
+        #     cc = flex.linear_correlation(ma1.data(), ma2.data()).coefficient()
+        #     print(f"{i=} {cc=:.3f}")
 
         # Log reindexing operators
         logger.info("Reindexing operators:")
@@ -220,6 +236,84 @@ def run(self):
             reindexing_ops, subgroup=self.cosym_analysis.best_subgroup
         )
 
+        # transform models into miller arrays
+        datasets_ = filtered_arrays_from_experiments_reflections(
+            self.experiments,
+            self.reflections,
+            outlier_rejection_after_filter=False,
+            partiality_threshold=self.params.partiality_threshold,
+        )
+        datasets_ = [
+            ma.as_non_anomalous_array().merge_equivalents().array() for ma in datasets_
+        ]
+        from dials.util.reference import intensities_from_reference_file
+        reference = intensities_from_reference_file(self.params.reference).as_non_anomalous_array().merge_equivalents().array().map_to_asu()
+        ref_inv_hand = reference.change_basis(sgtbx.change_of_basis_op("-c,-b,-a")).customized_copy(crystal_symmetry=reference.crystal_symmetry()).map_to_asu()
+        print(ref_inv_hand)
+        ma1, ma2 = reference.common_sets(ref_inv_hand)
+        corr = flex.linear_correlation(ma1.data(), ma2.data())
+        cc = corr.coefficient()
+        n = corr.n()
+        print(f"reference vs inv. hand: {cc=:.3f} {n=}")
+        ma1, ma2 = reference.expand_to_p1().common_sets(ref_inv_hand.expand_to_p1())
+        corr = flex.linear_correlation(ma1.data(), ma2.data())
+        cc = corr.coefficient()
+        n = corr.n()
+        print(f"reference vs inv. hand (P1): {cc=:.3f} {n=}")
+        # reference = reference.change_basis(sgtbx.change_of_basis_op("-c,-b,-a")).customized_copy(crystal_symmetry=reference.crystal_symmetry()).map_to_asu()
+        # ref = self.reference_intensities.change_basis(self._ref_cb_op.inverse()).customized_copy(space_group_info=self.params.space_group).map_to_asu()
+        # print(ref)
+        # ma1, ma2 = reference.common_sets(ref)
+        # corr = flex.linear_correlation(ma1.data(), ma2.data())
+        # cc = corr.coefficient()
+        # n = corr.n()
+        # print(f"reference vs ref: {cc=:.3f} {n=}")
+        for i, dset in enumerate(datasets_):
+            print(dset.size(), dset.map_to_asu().size(), dset.map_to_asu())
+            ma1, ma2 = dset.map_to_asu().common_sets(ref_inv_hand.map_to_asu())
+            print(f"{ma1.size()=} {ma2.size()=}")
+            corr = flex.linear_correlation(ma1.data(), ma2.data())
+            cc = corr.coefficient()
+            n = corr.n()
+            print(f"{i=} {cc=:.3f} {n=}")
+
+        print ("^" * 80)
+        ref = self.reference_intensities.customized_copy(space_group_info=self.params.space_group.change_basis(self._ref_cb_op))
+        print("1:", ref)
+        ref = reference.change_basis(self._ref_cb_op)
+        print("2:", ref)
+        # ref = reference.change_basis(sgtbx.change_of_basis_op("-c,-b,-a"))
+        subgroup = self.cosym_analysis.best_subgroup
+        print("@@@", str(subgroup["cb_op_inp_best"]), "@@@", str(self._ref_cb_op.inverse()),"@@@", str(self._ref_cb_op.inverse() * sgtbx.change_of_basis_op("-c,-b,-a")), "@@@")
+        print(ref)
+
+        # ma1 = reference.change_basis(self._ref_cb_op).map_to_asu()
+        # ma2 = reference.minimum_cell().map_to_asu()
+        # ma1, ma2 = ma1.common_sets(ma2)
+        # corr = flex.linear_correlation(ma1.data(), ma2.data())
+        # cc = corr.coefficient()
+        # n = corr.n()
+        # print(f"%%% {cc=:.3f} {n=} %%%")
+    
+        for i, (dset, op) in enumerate(zip(self.datasets[:-1], reindexing_ops[:-1])):
+            cb_op = sgtbx.change_of_basis_op(op)
+            print("1:", dset)
+            dset_ = dset.change_basis(cb_op)
+            # print("2:", dset_)
+            # dset_ = dset_.change_basis(subgroup["cb_op_inp_best"])
+            print("3:", dset_)
+            cb_op = subgroup["cb_op_inp_best"] * cb_op
+            # cb_op = self._ref_cb_op * cb_op
+            # cb_op =  cb_op * subgroup["cb_op_inp_best"]
+            dset = dset.change_basis(cb_op).customized_copy(crystal_symmetry=ref.crystal_symmetry()).map_to_asu()
+            print(dset)
+            ma1, ma2 = dset.common_sets(ref.map_to_asu())
+            print(f"{ma1.size()=} {ma2.size()=}")
+            corr = flex.linear_correlation(ma1.data(), ma2.data())
+            cc = corr.coefficient()
+            n = corr.n()
+            print(f"{i=} {cc=:.3f} {n=}")
+
     def export(self):
         """Output the datafiles for cosym.
 
@@ -255,6 +349,7 @@ def _apply_reindexing_operators(self, reindexing_ops, subgroup=None):
             expt = self._experiments[dataset_id]
             refl = self._reflections[dataset_id]
             if subgroup is not None:
+                print("Applying cb_op:", cb_op, subgroup["cb_op_inp_best"] * cb_op)
                 cb_op = subgroup["cb_op_inp_best"] * cb_op
                 expt.crystal = expt.crystal.change_basis(cb_op)
                 expt.crystal.set_space_group(
diff --git a/src/dials/command_line/symmetry.py b/src/dials/command_line/symmetry.py
index 6003f855a..d4b81093a 100644
--- a/src/dials/command_line/symmetry.py
+++ b/src/dials/command_line/symmetry.py
@@ -329,6 +329,7 @@ def symmetry(experiments, reflection_tables, params=None):
             params.relative_length_tolerance,
             params.absolute_angle_tolerance,
         )
+        print(f"{cb_ops=}")
         reflection_tables = eliminate_sys_absent(experiments, reflection_tables)
         experiments, reflection_tables = apply_change_of_basis_ops(
             experiments, reflection_tables, cb_ops
diff --git a/tests/util/test_image_grouping.py b/tests/util/test_image_grouping.py
index 7b845e09a..8e610419b 100644
--- a/tests/util/test_image_grouping.py
+++ b/tests/util/test_image_grouping.py
@@ -420,9 +420,11 @@ def test_real_cbf_example(tmp_path, dials_data):
     args = [shutil.which("dials.import"), f"template={fpath}"]
     result = subprocess.run(args, cwd=tmp_path, capture_output=True)
     assert not result.returncode and not result.stderr
+    print(result.stdout.decode())
 
     args = [shutil.which("dials.find_spots"), "imported.expt"]
     result = subprocess.run(args, cwd=tmp_path, capture_output=True)
+    print(result.stdout.decode())
     assert not result.returncode and not result.stderr
     args = [
         shutil.which("dials.ssx_index"),
@@ -435,22 +437,24 @@ def test_real_cbf_example(tmp_path, dials_data):
     ]
     result = subprocess.run(args, cwd=tmp_path, capture_output=True)
     assert not result.returncode and not result.stderr
+    print(result.stdout.decode())
 
     # First test on indexed data - here each image has its own imageset
     # only images 17001, 17002, 17003, 17004 get indexed, so expect these to be split into groups [1,0,1,0]
     fps = [FilePair(Path(tmp_path / "indexed.expt"), Path(tmp_path / "indexed.refl"))]
     fd = handler.split_files_to_groups(tmp_path, fps)
+    print(f"{fd=}")
 
     # with max lattices=2, 17001 has two lattices, 17002,17003,17004 have one
     assert list(fd.keys()) == ["group_1", "group_2"]
     filelist_1 = fd["group_1"]
-    assert len(filelist_1) == 1
+    assert len(filelist_1) == 1, filelist_1
     expts1 = load.experiment_list(filelist_1[0].expt)
     assert len(expts1) == 2
     assert expts1[0].imageset.get_path(0).split("_")[-1] == "17002.cbf"
     assert expts1[1].imageset.get_path(0).split("_")[-1] == "17004.cbf"
     filelist_2 = fd["group_2"]
-    assert len(filelist_2) == 1
+    assert len(filelist_2) == 1, filelist_2
     expts2 = load.experiment_list(filelist_2[0].expt)
     assert len(expts2) == 3
     assert expts2[0].imageset.get_path(0).split("_")[-1] == "17001.cbf"
@@ -463,14 +467,14 @@ def test_real_cbf_example(tmp_path, dials_data):
     fd = handler.split_files_to_groups(tmp_path, fps)
     assert list(fd.keys()) == ["group_1", "group_2"]
     filelist_1 = fd["group_1"]
-    assert len(filelist_1) == 1
+    assert len(filelist_1) == 1, filelist_1
     expts1 = load.experiment_list(filelist_1[0].expt)
     assert len(expts1) == 3
     assert expts1[0].scan.get_image_range()[0] == 17000
     assert expts1[1].scan.get_image_range()[0] == 17002
     assert expts1[2].scan.get_image_range()[0] == 17004
     filelist_2 = fd["group_2"]
-    assert len(filelist_2) == 1
+    assert len(filelist_2) == 1, filelist_2
     expts2 = load.experiment_list(filelist_2[0].expt)
     assert len(expts2) == 2
     assert expts2[0].scan.get_image_range()[0] == 17001
